# -*- coding: utf-8 -*-
"""IEA_Data_train_updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VT5f14SM-mFMIHUQUs1RgTeG_py2rX50

# Preprocessing IEA Electricity Statistics Data
"""

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""## Load the Dataset

## Data Preprocessing Insights

### Key Steps:
1. **Data Cleaning**: Removed unnecessary rows and handled missing values.
2. **Time-Series Aggregation**: Grouped data by months to create a continuous time-series.
3. **Decomposition**: Separated data into trend, seasonality, and residual components for independent analysis.
"""

# Load the dataset
file_path = "/content/MES_0824.csv"  # Update with your file path
data = pd.read_csv(file_path, encoding='latin1', skiprows=7)

"""## Clean and Structure Data"""

# Assign proper column names
data.columns = data.iloc[0]  # Use the first row as headers
data = data[1:]  # Remove the first row
data.columns = ["Country", "Time", "Balance", "Product", "Value", "Unit"]

"""## Convert Data Types"""

# Convert 'Value' column to numeric
data["Value"] = pd.to_numeric(data["Value"], errors="coerce")

# Drop rows with NaN in 'Value'
data = data.dropna(subset=["Value"])

# Convert 'Time' column to datetime
data['Time'] = pd.to_datetime(data['Time'])

# 1. Distribution of energy production values
plt.figure(figsize=(12, 6))
sns.histplot(data['Value'], bins=50, kde=True, color="blue")
plt.title('Distribution of Energy Production (GWh)')
plt.xlabel('Energy Production (GWh)')
plt.ylabel('Frequency')
plt.grid()
plt.show()

# 2. Time-series plot of energy production
plt.figure(figsize=(15, 6))
sns.lineplot(x='Time', y='Value', data=data, marker="o", label='Energy Production')
plt.title('Energy Production Over Time')
plt.xlabel('Time')
plt.ylabel('Energy Production (GWh)')
plt.legend()
plt.grid()
plt.show()

# 3. Boxplot by month to visualize seasonality
data['Month'] = data['Time'].dt.month_name()  # Now 'Time' is datetime, this will work
plt.figure(figsize=(12, 6))
sns.boxplot(x='Month', y='Value', data=data, order=[
    'January', 'February', 'March', 'April', 'May', 'June',
    'July', 'August', 'September', 'October', 'November', 'December'
], palette="coolwarm")
plt.title('Seasonal Variations in Energy Production')
plt.xlabel('Month')
plt.ylabel('Energy Production (GWh)')
plt.grid()
plt.show()

# 4. Heatmap of production values by year and month
data['Year'] = data['Time'].dt.year
data['Month_Number'] = data['Time'].dt.month

heatmap_data = data.pivot_table(
    values='Value',
    index='Year',
    columns='Month_Number',
    aggfunc='sum'
)

plt.figure(figsize=(12, 8))
sns.heatmap(heatmap_data, annot=False, fmt=".0f", cmap='coolwarm', cbar_kws={'label': 'Energy Production (GWh)'})
plt.title('Yearly and Monthly Energy Production Heatmap')
plt.xlabel('Month')
plt.ylabel('Year')
plt.show()

# Filter data to include only the top 5 countries with the highest total energy production
top_countries = data.groupby("Country")["Value"].sum().nlargest(10).index
data_top_countries = data[data["Country"].isin(top_countries)]

# 5 . Plot the distribution for the top 5 countries
plt.figure(figsize=(15, 6))
sns.boxplot(x='Country', y='Value', data=data_top_countries, palette="viridis")
plt.title('Energy Production Distribution by Top 5 Countries')
plt.xlabel('Country')
plt.ylabel('Energy Production (GWh)')
plt.xticks(rotation=45)
plt.grid()
plt.show()

"""## Extract Relevant Data"""

# Extract data for "Net Electricity Production" only
net_electricity = data[data["Balance"] == "Net Electricity Production"]

"""## Aggregate Data by Country and Product"""

country_product_summary = net_electricity.groupby(["Country", "Product"]).agg(
    {"Value": "sum"}
).reset_index()

"""## Plot Trends"""

plt.figure(figsize=(12, 8))
sns.barplot(data=country_product_summary, x="Country", y="Value", hue="Product")
plt.xticks(rotation=45)
plt.title("Net Electricity Production by Country and Product")
plt.xlabel("Country")
plt.ylabel("Electricity Production (GWh)")
plt.legend(title="Product")
plt.tight_layout()
plt.show()

data.head()

# Ensure Time is parsed as a datetime column
data['Time'] = pd.to_datetime(data['Time'], errors='coerce')

# Extract the month from the "Time" column
data["Month_Number"] = data['Time'].dt.month

# Apply sine and cosine transformations to the months
data["Sine_Month"] = np.sin(2 * np.pi * data["Month_Number"] / 12)
data["Cosine_Month"] = np.cos(2 * np.pi * data["Month_Number"] / 12)

# Display the first few rows to ensure correct parsing
data.head()

from statsmodels.tsa.seasonal import seasonal_decompose

# Ensure the 'Time' column is in a proper datetime format
data["Time"] = pd.to_datetime(data["Time"], errors="coerce", format='%B %Y')

# Aggregate data by month (sum of 'Value' per month)
monthly_data = data.groupby("Time")["Value"].sum().reset_index()

# Set the time column as the index
monthly_data.set_index("Time", inplace=True)

# Decompose the time series into trend, seasonality, and residuals
decomposition = seasonal_decompose(monthly_data["Value"], model="additive", period=12)

# Extract components
trend = decomposition.trend
seasonal = decomposition.seasonal
residual = decomposition.resid

# Combine components into a single DataFrame for visualization
decomposed_df = pd.DataFrame({
    "Value": monthly_data["Value"],
    "Trend": trend,
    "Seasonal": seasonal,
    "Residual": residual
})


# Plot the decomposed components
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))

plt.subplot(411)
plt.plot(decomposed_df["Value"], label="Original Data")
plt.legend(loc="upper left")

plt.subplot(412)
plt.plot(decomposed_df["Trend"], label="Trend", color="orange")
plt.legend(loc="upper left")

plt.subplot(413)
plt.plot(decomposed_df["Seasonal"], label="Seasonality", color="green")
plt.legend(loc="upper left")

plt.subplot(414)
plt.plot(decomposed_df["Residual"], label="Residual", color="red")
plt.legend(loc="upper left")

plt.tight_layout()
plt.show()

# Include all original columns in the decomposed DataFrame
decomposed_df_full = decomposed_df.copy()

# Re-add the original columns (assuming they were removed earlier)
decomposed_df_full["Country"] = data["Country"].values[:len(decomposed_df_full)]
decomposed_df_full["Balance"] = data["Balance"].values[:len(decomposed_df_full)]
decomposed_df_full["Product"] = data["Product"].values[:len(decomposed_df_full)]
decomposed_df_full["Unit"] = data["Unit"].values[:len(decomposed_df_full)]
decomposed_df_full["Sine_Month"] = data["Sine_Month"].values[:len(decomposed_df_full)]
decomposed_df_full["Cosine_Month"] = data["Cosine_Month"].values[:len(decomposed_df_full)]

decomposed_df_full.head()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
import numpy as np
import pandas as pd

# Assuming 'decomposed_df_full' is your decomposed data DataFrame
# Prepare data for trend forecasting
trend_data = decomposed_df_full["Trend"].dropna().values
trend_scaler = MinMaxScaler()
trend_data_scaled = trend_scaler.fit_transform(trend_data.reshape(-1, 1))

# Create lagged features for supervised learning
def create_lagged_features(data, lag=12):
    X, y = [], []
    for i in range(lag, len(data)):
        X.append(data[i-lag:i])
        y.append(data[i])
    return np.array(X), np.array(y)

# Define lag and prepare trend data
lag = 12
X_trend, y_trend = create_lagged_features(trend_data_scaled, lag=lag)

# Split into train and test sets
X_train_trend, X_test_trend, y_train_trend, y_test_trend = train_test_split(
    X_trend, y_trend, test_size=0.2, random_state=42
)

# Build and train an LSTM model for trend forecasting
trend_model = Sequential([
    LSTM(50, activation='relu', input_shape=(X_train_trend.shape[1], X_train_trend.shape[2])),
    Dense(1)
])
trend_model.compile(optimizer='adam', loss='mse')
trend_model.fit(X_train_trend, y_train_trend, epochs=20, batch_size=16, verbose=1)

# Prepare data for seasonality forecasting
seasonal_data = decomposed_df_full["Seasonal"].dropna().values
seasonal_scaler = MinMaxScaler()
seasonal_data_scaled = seasonal_scaler.fit_transform(seasonal_data.reshape(-1, 1))

X_seasonal = decomposed_df_full[["Sine_Month", "Cosine_Month"]].dropna().values[:len(seasonal_data_scaled)]
y_seasonal = seasonal_data_scaled

X_train_seasonal, X_test_seasonal, y_train_seasonal, y_test_seasonal = train_test_split(
    X_seasonal, y_seasonal, test_size=0.2, random_state=42
)

# Build seasonality model
season_model = Sequential([
    Dense(32, activation='relu', input_dim=2),
    Dense(16, activation='relu'),
    Dense(1)
])
season_model.compile(optimizer='adam', loss='mse')
season_model.fit(X_train_seasonal, y_train_seasonal, epochs=20, batch_size=16, verbose=1)

# Forecast both components
trend_forecast = trend_model.predict(X_test_trend)
season_forecast = season_model.predict(X_test_seasonal)

# Combine forecasts (denormalize trend and season forecasts)
trend_forecast_denorm = trend_scaler.inverse_transform(trend_forecast)
season_forecast_denorm = seasonal_scaler.inverse_transform(season_forecast)

# Determine the minimum length
min_length = min(len(trend_forecast_denorm.flatten()), len(season_forecast_denorm.flatten()))

# Truncate both arrays to the same length
trend_forecast_aligned = trend_forecast_denorm.flatten()[:min_length]
season_forecast_aligned = season_forecast_denorm.flatten()[:min_length]

# Combine the aligned forecasts
forecast_combined = trend_forecast_aligned + season_forecast_aligned

# Display the first 10 combined forecasts
print("First 10 Combined Forecasts:", forecast_combined[:10])

"""
## Time-Series Forecasting with Train-Test Split and Validation

### Key Steps:
1. **Model Training**:
   - LSTM for trend forecasting.
   - Neural network for seasonal forecasting.
2. **Validation**:
   - Metrics used: MAE, RMSE, and visual validation.
   - Compared predictions with baseline models (Naïve and Moving Average).
3. **Visualization**:
   - Combined trend and seasonality components to plot forecasts.
"""

import matplotlib.pyplot as plt
import numpy as np

# Generate a sequence of inputs for the next 12 months (future months)
future_months = np.arange(1, 13)
future_sine = np.sin(2 * np.pi * future_months / 12)
future_cosine = np.cos(2 * np.pi * future_months / 12)
X_future_seasonal = np.column_stack((future_sine, future_cosine))

# Predict the seasonality for the next 12 months
future_seasonal_scaled = season_model.predict(X_future_seasonal)
future_seasonal = seasonal_scaler.inverse_transform(future_seasonal_scaled)

# Generate lagged trend data for the next 12 months
# Start with the last 12 months of the trend forecast data
last_trend = trend_forecast[-12:]

# Iteratively forecast the next 12 months
future_trend = []
current_input = last_trend
for _ in range(12):
    next_trend = trend_model.predict(current_input.reshape(1, -1, 1))
    future_trend.append(next_trend[0][0])
    # Shift the input window
    current_input = np.append(current_input[1:], next_trend).reshape(-1, 1)

# Denormalize the trend forecast
future_trend = trend_scaler.inverse_transform(np.array(future_trend).reshape(-1, 1)).flatten()

# Combine the forecasts
future_combined = future_trend + future_seasonal.flatten()

# Plot the forecasts
plt.figure(figsize=(12, 8))

# Plot trend forecast
plt.plot(range(1, 13), future_trend, label="Trend Forecast", marker="o", color="blue")

# Plot seasonal forecast
plt.plot(range(1, 13), future_seasonal.flatten(), label="Seasonal Forecast", marker="o", color="green")

# Plot combined forecast
plt.plot(range(1, 13), future_combined, label="Combined Forecast", marker="o", color="red")

# Customize the plot
plt.title("Energy Production Forecast for Next Year")
plt.xlabel("Months")
plt.ylabel("Energy Production (GWh)")
plt.xticks(range(1, 13), [
    "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
])
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Desnormalizar os valores reais de tendência
y_test_trend_denorm = trend_scaler.inverse_transform(y_test_trend)

# Desnormalizar os valores reais de sazonalidade
y_test_seasonal_denorm = seasonal_scaler.inverse_transform(y_test_seasonal)

# Garantir que todos os arrays tenham o mesmo tamanho
min_length = min(len(y_test_trend_denorm), len(y_test_seasonal_denorm), len(forecast_combined))

# Truncar os arrays para o tamanho mínimo
y_test_trend_aligned = y_test_trend_denorm[:min_length]
y_test_seasonal_aligned = y_test_seasonal_denorm[:min_length]
forecast_combined_aligned = forecast_combined[:min_length]

# Combinar os componentes reais
y_test_combined = y_test_trend_aligned.flatten() + y_test_seasonal_aligned.flatten()

# Criar eixo de tempo
time_axis = np.arange(len(y_test_combined))

# Plotar os valores reais e as previsões
plt.figure(figsize=(14, 7))
plt.plot(time_axis, y_test_combined, label='Valores Reais', marker='o', linestyle='-')
plt.plot(time_axis, forecast_combined_aligned, label='Previsões do Modelo', marker='x', linestyle='--')
plt.title('Comparação entre Previsões e Valores Reais da Produção de Energia')
plt.xlabel('Tempo (meses)')
plt.ylabel('Produção de Energia (GWh)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Calcular e exibir as métricas de desempenho
mae = mean_absolute_error(y_test_combined, forecast_combined_aligned)
rmse = np.sqrt(mean_squared_error(y_test_combined, forecast_combined_aligned))
print(f'MAE: {mae:.2f} GWh')
print(f'RMSE: {rmse:.2f} GWh')

# prompt: i want to commit this code to a github repo

# You can directly copy and paste the code into a Python file (e.g., energy_forecasting.py)
# Then, create a new repository on GitHub, initialize it, add the file and commit the changes.


# Example commands (replace with your actual paths and repository name):

# 1. Create the repository on GitHub (manually)

# 2. On your local machine:
# !git init
# !git add energy_forecasting.py
# !git commit -m "Initial commit of energy forecasting code"

# 3. Connect your local repository to your remote repository on GitHub:
# !git remote add origin <your_repository_URL>  # Replace <your_repository_URL> with your actual GitHub repo URL

# 4. Push your code to GitHub:
# !git push -u origin main  # Or your default branch name if it's not 'main'


# Note: Before running git commands, make sure you have Git installed and configured.